{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More File Processing\n",
    "\n",
    "So far we've learned looping, but what is it good for really?  Today we will see our first application of a for loop, that will make sense!  Today, we will be reading a file into memory, treating each of the lines of the file as strings and applying various processing techniques to them.  We'll first go over reading text into memory and then we'll go over some string processing techniques. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"alice_in_wonderland.txt\",\"r\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code reads our text into memory for processing.  We are now ready to start processing and analyzing our piece of text!\n",
    "\n",
    "There are lots of methods built into the python language for processing strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['capitalize',\n",
       " 'casefold',\n",
       " 'center',\n",
       " 'count',\n",
       " 'encode',\n",
       " 'endswith',\n",
       " 'expandtabs',\n",
       " 'find',\n",
       " 'format',\n",
       " 'format_map',\n",
       " 'index',\n",
       " 'isalnum',\n",
       " 'isalpha',\n",
       " 'isdecimal',\n",
       " 'isdigit',\n",
       " 'isidentifier',\n",
       " 'islower',\n",
       " 'isnumeric',\n",
       " 'isprintable',\n",
       " 'isspace',\n",
       " 'istitle',\n",
       " 'isupper',\n",
       " 'join',\n",
       " 'ljust',\n",
       " 'lower',\n",
       " 'lstrip',\n",
       " 'maketrans',\n",
       " 'partition',\n",
       " 'replace',\n",
       " 'rfind',\n",
       " 'rindex',\n",
       " 'rjust',\n",
       " 'rpartition',\n",
       " 'rsplit',\n",
       " 'rstrip',\n",
       " 'split',\n",
       " 'splitlines',\n",
       " 'startswith',\n",
       " 'strip',\n",
       " 'swapcase',\n",
       " 'title',\n",
       " 'translate',\n",
       " 'upper',\n",
       " 'zfill']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[elem for elem in dir(str()) if \"__\" not in elem]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will be going over:\n",
    "\n",
    "* lower\n",
    "* upper\n",
    "* islower\n",
    "* isnumeric\n",
    "* isupper\n",
    "* split\n",
    "* splitlines\n",
    "* translate\n",
    "* strip\n",
    "* lstrip\n",
    "* rstrip\n",
    "* isalnum\n",
    "* isalpha\n",
    "* isdecimal\n",
    "* isspace\n",
    "* isdigit\n",
    "* find\n",
    "* startswith\n",
    "* endswith\n",
    "* captialize\n",
    "\n",
    "This may seem like a lot but don't worry!  It's really only a few categories of things :)\n",
    "\n",
    "Let's get started  with `split` and then move onto the `startswith`, `endswith` methods, because those are pretty easy to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Project Gutenberg's Alice's Adventures in Wonderland, by Lewis Carroll\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"alice_in_wonderland.txt\",\"r\") as f:\n",
    "    text = f.read()\n",
    "lines = text.split(\"\\n\")\n",
    "print(type(lines))\n",
    "lines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `split` method allows us to specify a character to split the text on.  Every time the character is seen, it will be split at that character.  Here's a more worked example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['For this string', \" we'll split\", ' on', ' commas', ' okay?']\n",
      "For this string\n",
      " we'll split\n",
      " on\n",
      " commas\n",
      " okay?\n"
     ]
    }
   ],
   "source": [
    "string = \"For this string, we'll split, on, commas, okay?\"\n",
    "listing = string.split(\",\")\n",
    "print(listing)\n",
    "for elem in listing:\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for every comma in the string, the string is split on that character.  By default, if you don't pass in anything, then the split function splits on white space characters.\n",
    "\n",
    "Now that we can split on specific strings, let's look at the `startswith` and `endswith` methods.  These methods will be used to do some baseline analysis of the text!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greeting_words = [\"Hello\", \"Hi\", \"How are you?\"]\n",
    "goodbye_words = [\"Goodbye\", \"See you\", \"See you!\"]\n",
    "\n",
    "with open(\"alice_in_wonderland.txt\",\"r\") as f:\n",
    "    text = f.read()\n",
    "lines = text.split(\"\\n\")\n",
    "greetings = 0\n",
    "goodbyes = 0\n",
    "for line in lines:\n",
    "    if any([line.startswith(elem) for elem in greeting_words]):\n",
    "        greetings += 1\n",
    "    if any([line.startswith(elem) for elem in goodbye_words]):\n",
    "        goodbyes += 1\n",
    "greetings, goodbyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greeting_words = [\"Hello\", \"Hi\", \"How are you?\"]\n",
    "goodbye_words = [\"Goodbye\", \"See you\", \"See you!\"]\n",
    "\n",
    "with open(\"alice_in_wonderland.txt\",\"r\") as f:\n",
    "    text = f.read()\n",
    "lines = text.split(\"\\n\")\n",
    "greetings = 0\n",
    "goodbyes = 0\n",
    "for line in lines:\n",
    "    if any([line.endswith(elem) for elem in greeting_words]):\n",
    "        greetings += 1\n",
    "    if any([line.endswith(elem) for elem in goodbye_words]):\n",
    "        goodbyes += 1\n",
    "greetings, goodbyes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like our set of greetings and goodbyes didn't yield any results, I guess folks aren't very friendly!  Let's expand the list by ignoring case, but how do we do that?!  Enter `upper` and `lower`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"LET'S MAKE THIS TEXT ALL UPPERCASE\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"Let's make this text all uppercase\"\n",
    "string.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"let's make this text all lowercase\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"Let's make ThIs tExT all lowercase\"\n",
    "string.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if any of the text words for upper or lower case versions of the text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greeting_words = [\"hello\", \"hi\", \"how are you?\"]\n",
    "goodbye_words = [\"goodbye\", \"see you\", \"see you!\"]\n",
    "\n",
    "with open(\"alice_in_wonderland.txt\",\"r\") as f:\n",
    "    text = f.read()\n",
    "lines = text.split(\"\\n\")\n",
    "greetings = 0\n",
    "goodbyes = 0\n",
    "for line in lines:\n",
    "    line = line.lower()\n",
    "    if any([line.startswith(elem) for elem in greeting_words]):\n",
    "        greetings += 1\n",
    "    if any([line.startswith(elem) for elem in goodbye_words]):\n",
    "        goodbyes += 1\n",
    "    if any([line.endswith(elem) for elem in greeting_words]):\n",
    "        greetings += 1\n",
    "    if any([line.endswith(elem) for elem in goodbye_words]):\n",
    "        goodbyes += 1\n",
    "greetings, goodbyes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pay dirt!  We got some greetings and goodbyes!  It turns out sometimes, people are friendly in alice in wonderland after all!  Now let's see if any of our greeting words or goodbye words are anywhere on any line in the text.  We'll use find to do this :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "string = \"Hello there friend\"\n",
    "print(string.find(\"there\"))\n",
    "print(string.find(\"whatever\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So find either, finds the occurrence of the string or returns -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(736, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greeting_words = [\"hello\", \"hi\", \"how are you?\"]\n",
    "goodbye_words = [\"goodbye\", \"see you\", \"see you!\"]\n",
    "\n",
    "with open(\"alice_in_wonderland.txt\",\"r\") as f:\n",
    "    text = f.read()\n",
    "lines = text.split(\"\\n\")\n",
    "greetings = 0\n",
    "goodbyes = 0\n",
    "for line in lines:\n",
    "    line = line.lower()\n",
    "    greetings_found = [elem for elem in greeting_words if line.find(elem) != -1]\n",
    "    goodbyes_found = [elem for elem in goodbye_words if line.find(elem) != -1]\n",
    "    greetings += len(greetings_found)\n",
    "    goodbyes += len(goodbyes_found)\n",
    "greetings, goodbyes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above method we are able to effectively search the text, in it's entirety for occurrences of the six phrases of interest!  At this point, we've likely found all the instances of those words.  But this leads us to a general point.  We can search text for words or phrases!!!\n",
    "\n",
    "Now let's use our new found powers to something really cool - let's spell correct a bunch of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocorrect import spell\n",
    "import time\n",
    "with open(\"alice_in_wonderland.txt\",\"r\") as f:\n",
    "    text = f.read()\n",
    "lines = text.split(\"\\n\")\n",
    "new_lines = []\n",
    "total_misspellings = 0\n",
    "misspellings_per_line = []\n",
    "start = time.time()\n",
    "for index,line in enumerate(lines):\n",
    "    tokens = line.split()\n",
    "    new_tokens = []\n",
    "    misspellings = 0\n",
    "    for token in tokens:\n",
    "        correct_spelling = spell(token)\n",
    "        if correct_spelling != token:\n",
    "            total_misspellings += 1\n",
    "            misspellings += 1\n",
    "        new_tokens.append(correct_spelling)\n",
    "    misspellings_per_line.append(misspellings)\n",
    "    new_string = \" \".join(new_tokens)\n",
    "    new_lines.append(new_string)\n",
    "new_text = \"\\n\".join(new_lines)\n",
    "with open(\"correctly_spelled_alice_in_wonderland.txt\", \"w\") as f:\n",
    "    f.write(new_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for fun, let's do a little bit of analysis on the number of misspellings on our text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6383832976445396\n",
      "6121\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(statistics.mean(misspellings_per_line))\n",
    "print(total_misspellings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we made a ton of corrections to this document!  Pretty good.  Okay, okay.  So if we turn this into code, then we'll still need to point our code at a bunch of files, can we do better?\n",
    "\n",
    "Turns out we can!  Remember last week, when we learned how to move between directories, let's apply some of that knowledge now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently process /Users/ericschles/Documents/projects/python_courses/an_introduction_to_python\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-8355179eb217>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mdirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdirectory\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraversed_dirs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mcorrectly_spelled_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspell_correct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrectly_spelled_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-8355179eb217>\u001b[0m in \u001b[0;36mspell_correct\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mnew_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mnew_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mnew_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mnew_lines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_line\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/autocorrect/__init__.py\u001b[0m in \u001b[0;36mspell\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     candidates = (common([word]) or exact([word]) or known([word]) or\n\u001b[0;32m---> 23\u001b[0;31m                   \u001b[0mknown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble_typos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                   [word])\n\u001b[1;32m     25\u001b[0m     \u001b[0mcorrection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNLP_COUNTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/autocorrect/word.py\u001b[0m in \u001b[0;36mdouble_typos\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdouble_typos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;34m\"\"\"letter combinations two typos away from word\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         return {e2 for e1 in self.typos()\n\u001b[0m\u001b[1;32m     72\u001b[0m                 for e2 in Word(e1).typos()}\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/autocorrect/word.py\u001b[0m in \u001b[0;36m<setcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;34m\"\"\"letter combinations two typos away from word\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         return {e2 for e1 in self.typos()\n\u001b[0;32m---> 72\u001b[0;31m                 for e2 in Word(e1).typos()}\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from autocorrect import spell\n",
    "\n",
    "def spell_correct(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        text = f.read()\n",
    "        lines = text.split(\"\\n\")\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        tokens = line.split()\n",
    "        new_tokens = []\n",
    "        for token in tokens:\n",
    "            new_tokens.append(spell(token))\n",
    "        new_line = \" \".join(new_tokens)\n",
    "        new_lines.append(new_line)\n",
    "    return \"\\n\".join(new_lines)\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "dirs = []\n",
    "traversed_dirs = [current_dir]\n",
    "previous_dir = \"\"\n",
    "while current_dir != previous_dir:\n",
    "    print(\"currently process\", current_dir)\n",
    "    files = [os.path.abspath(file) for file in glob(\"*\") if os.path.isfile(file)]\n",
    "    dirs += [os.path.abspath(directory) for directory in glob(\"*\") if os.path.isdir(directory)]\n",
    "    dirs = [directory for directory in dirs if directory not in traversed_dirs]\n",
    "    print(\"beginning file processing\")\n",
    "    for file in files:\n",
    "        correctly_spelled_file = spell_correct(file)\n",
    "        with open(file,\"w\") as f:\n",
    "            f.write(correctly_spelled_file)\n",
    "    print(\"wrote out all files with spell correction\")\n",
    "    previous_dir = current_dir\n",
    "    current_dir = dirs.pop()\n",
    "    traversed_dirs.append(current_dir)\n",
    "    os.chdir(current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
